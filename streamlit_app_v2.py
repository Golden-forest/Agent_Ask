"""
æ™ºèƒ½æ¾„æ¸…Agent - ç¾åŒ–ç‰ˆStreamlitç•Œé¢
ä½¿ç”¨è‡ªå®šä¹‰æ ·å¼ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
"""

import os
import streamlit as st
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from langchain_openai import ChatOpenAI
from streamlit_ui_config import (
    apply_custom_style,
    create_header,
    create_sidebar,
    create_footer,
    show_success_message
)

load_dotenv()

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_custom_style()

# è®¾ç½®LLM
@st.cache_resource
def get_llm():
    """ç¼“å­˜LLMå®ä¾‹"""
    return ChatOpenAI(
        model="deepseek-chat",
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        openai_api_base=os.getenv("DEEPSEEK_BASE_URL"),
    )


def load_prompt_from_file(file_path: str) -> str:
    """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ“…é•¿è§£å†³å„ç§æŠ€æœ¯é—®é¢˜ã€‚"


@st.cache_resource
def create_conversation_agent():
    """åˆ›å»ºå¯¹è¯Agentï¼ˆç¼“å­˜ï¼‰"""
    prompt_content = load_prompt_from_file('example_prompt_template.txt')

    agent = Agent(
        role='Claude Codeç¼–ç¨‹åŠ©æ‰‹',
        goal='å¸®åŠ©ç”¨æˆ·è§£å†³ç¼–ç¨‹é—®é¢˜ï¼Œæä¾›é«˜è´¨é‡çš„ä»£ç å’Œè§£å†³æ–¹æ¡ˆ',
        backstory=prompt_content,
        verbose=False,
        llm=get_llm(),
        allow_delegation=False
    )
    return agent


def get_ai_response(user_input: str, agent):
    """è·å–AIå›å¤"""
    try:
        task = Task(
            description=f'ç”¨æˆ·è¯¢é—®ï¼š{user_input}',
            agent=agent,
            expected_output='æä¾›ä¸“ä¸šã€è¯¦ç»†çš„å›ç­”ï¼ŒåŒ…å«ä»£ç ç¤ºä¾‹å’Œè§£é‡Š'
        )

        crew = Crew(
            agents=[agent],
            tasks=[task],
            verbose=False
        )

        result = crew.kickoff()
        return result, True
    except Exception as e:
        return f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼š{str(e)}", False


def main():
    """ä¸»ç•Œé¢"""

    # åˆ›å»ºå¤´éƒ¨
    create_header(
        title="ğŸ¤– éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹",
        subtitle="é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„æé—®ï¼Œå¸®åŠ©æ‚¨æ˜ç¡®çœŸå®éœ€æ±‚"
    )

    # åˆ›å»ºAgent
    agent = create_conversation_agent()

    # åˆ›å»ºä¾§è¾¹æ 
    example_questions = create_sidebar()

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ã€‚\n\n"
                          "æˆ‘å°†é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„æé—®ï¼Œå¸®åŠ©ä½ æ˜ç¡®å’Œæ¾„æ¸…çœŸå®éœ€æ±‚ã€‚\n\n"
                          "ğŸ’¡ **ä½¿ç”¨æ–¹å¼ï¼š**\n"
                          "1. è¯·æè¿°ä½ çš„åˆå§‹æƒ³æ³•æˆ–éœ€æ±‚\n"
                          "2. æˆ‘ä¼šæå‡ºå…³é”®é—®é¢˜å¸®åŠ©ä½ æ¾„æ¸…\n"
                          "3. æä¾›A/B/C/Dé€‰é¡¹ä¾›ä½ é€‰æ‹©\n"
                          "4. å½“éœ€æ±‚è¶³å¤Ÿæ¸…æ™°æ—¶ï¼Œè¾“å…¥\"Accept\"è·å–å®Œæ•´çš„éœ€æ±‚åˆ†æ\n\n"
                          "è¯·å¼€å§‹æè¿°ä½ çš„éœ€æ±‚å§ï¼"
            }
        ]

    # æ˜¾ç¤ºèŠå¤©å†å²
    chat_container = st.container()
    with chat_container:
        for i, message in enumerate(st.session_state.messages):
            with st.chat_message(message["role"]):
                # æ ¼å¼åŒ–è¾“å‡ºï¼Œä¿ç•™Markdown
                st.markdown(message["content"])

    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    prompt = st.chat_input("ğŸ’¬ è¯·æè¿°ä½ çš„éœ€æ±‚æˆ–æƒ³æ³•...")

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)

        # è·å–AIå›å¤
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” AIæ­£åœ¨æ€è€ƒ..."):
                response, success = get_ai_response(prompt, agent)

            if success:
                # æ˜¾ç¤ºå›å¤
                st.markdown(response)

                # æ·»åŠ AIå›å¤åˆ°å†å²
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response
                })
            else:
                st.error(response)

        # é‡æ–°è¿è¡Œä»¥åˆ·æ–°ç•Œé¢
        st.rerun()

    # ç¤ºä¾‹é—®é¢˜åŒºåŸŸï¼ˆå¯é€‰å±•å¼€ï¼‰
    with st.expander("ğŸ’¡ æŸ¥çœ‹ç¤ºä¾‹éœ€æ±‚", expanded=False):
        st.markdown("ç‚¹å‡»ä¸‹æ–¹éœ€æ±‚å¿«é€Ÿå¼€å§‹æ¾„æ¸…ï¼š")
        for i, question in enumerate(example_questions, 1):
            if st.button(f"{i}. {question}", key=f"example_{i}"):
                # æ¨¡æ‹Ÿç‚¹å‡»é—®é¢˜
                prompt = question
                st.rerun()

    # æ·»åŠ å¿«æ·æ“ä½œ
    col1, col2, col3 = st.columns([1, 1, 1])

    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", type="secondary", use_container_width=True):
            st.session_state.messages = [
                {
                    "role": "assistant",
                    "content": "âœ… å¯¹è¯å·²æ¸…ç©ºã€‚æœ‰ä»€ä¹ˆæ–°é—®é¢˜å—ï¼Ÿ"
                }
            ]
            show_success_message("å¯¹è¯å†å²å·²æ¸…ç©º")
            st.rerun()

    with col2:
        if st.button("ğŸ“Š æŸ¥çœ‹ç»Ÿè®¡", type="secondary", use_container_width=True):
            msg_count = len(st.session_state.messages)
            st.info(f"å½“å‰å¯¹è¯å…± {msg_count} æ¡æ¶ˆæ¯")

    with col3:
        if st.button("ğŸ“ å¯¼å‡ºå¯¹è¯", type="secondary", use_container_width=True):
            # åˆ›å»ºå¯¹è¯æ–‡æœ¬
            chat_text = "\n\n".join([
                f"{'ç”¨æˆ·' if msg['role'] == 'user' else 'AIåŠ©æ‰‹'}:\n{msg['content']}"
                for msg in st.session_state.messages
            ])

            # æä¾›ä¸‹è½½
            st.download_button(
                label="ğŸ’¾ ä¸‹è½½å¯¹è¯è®°å½•",
                data=chat_text,
                file_name=f"chat_history_{len(st.session_state.messages)}_messages.txt",
                mime="text/plain",
                use_container_width=True
            )

    # åˆ›å»ºé¡µè„š
    create_footer()


if __name__ == "__main__":
    main()
