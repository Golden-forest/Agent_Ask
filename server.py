"""
FastAPIåç«¯æœåŠ¡
ä¸ºéœ€æ±‚æ¾„æ¸…åŠ©æ‰‹æä¾›RESTful APIæ¥å£å’ŒWebSocketå®æ—¶é€šä¿¡
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import asyncio
from datetime import datetime
from dotenv import load_dotenv
import socketio

from langchain_openai import ChatOpenAI
from search import search_requirement_context

load_dotenv()

# FastAPIåº”ç”¨
app = FastAPI(
    title="éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹API",
    description="AIéœ€æ±‚æ¾„æ¸…åŠ©æ‰‹çš„RESTful APIæ¥å£",
    version="1.0.0"
)

# Socket.IOè®¾ç½®
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*')
socket_app = socketio.ASGIApp(sio, app)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:8501", "http://localhost:8504", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ¨¡å‹
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    conversation_history: List[ChatMessage] = []
    enable_search: bool = True

class ChatResponse(BaseModel):
    response: str
    timestamp: str
    search_info: Optional[str] = None
    conversation_id: str

class RequirementAnalysis(BaseModel):
    original_requirement: str
    optimized_requirement: str
    key_questions: List[Dict[str, str]]
    suggestions: List[str]

# å…¨å±€å˜é‡
llm = ChatOpenAI(
    model="deepseek-chat",
    openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
    openai_api_base=os.getenv("DEEPSEEK_BASE_URL"),
    streaming=False
)

# å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰
conversations: Dict[str, List[ChatMessage]] = {}

def generate_conversation_id() -> str:
    """ç”Ÿæˆå¯¹è¯ID"""
    return f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

async def save_conversation(conversation_id: str, user_message: str, ai_response: str):
    """ä¿å­˜å¯¹è¯å†å²"""
    if conversation_id not in conversations:
        conversations[conversation_id] = []

    conversations[conversation_id].extend([
        ChatMessage(role="user", content=user_message),
        ChatMessage(role="assistant", content=ai_response)
    ])

# Socket.IO äº‹ä»¶å¤„ç†
@sio.event
async def connect(sid, environ):
    print(f"Client connected: {sid}")

@sio.event
async def disconnect(sid):
    print(f"Client disconnected: {sid}")

@sio.event
async def chat_message(sid, data):
    """å¤„ç†èŠå¤©æ¶ˆæ¯å¹¶æµå¼è¿”å›"""
    try:
        message = data.get('message')
        history_data = data.get('history', [])
        enable_search = data.get('enable_search', True)
        conversation_id = data.get('conversation_id') or generate_conversation_id()
        
        # è½¬æ¢å†å²è®°å½•
        history = [{"role": msg['role'], "content": msg['content']} for msg in history_data]
        
        # æœç´¢ä¿¡æ¯
        search_info = ""
        if (enable_search and
            len(history) == 0 and
            len(message) > 10 and
            os.getenv("SERPER_API_KEY")):
            try:
                await sio.emit('search_status', {'status': 'searching'}, room=sid)
                # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æœç´¢å‡½æ•°
                search_info = await asyncio.to_thread(search_requirement_context, message)
                await sio.emit('search_status', {'status': 'completed', 'info': search_info}, room=sid)
            except Exception as e:
                print(f"Search error: {e}")
                await sio.emit('search_status', {'status': 'error', 'error': str(e)}, room=sid)

        # âš ï¸ ä¿®æ”¹æç¤ºè¯çš„é‡è¦è§„åˆ™å’Œæ³¨æ„äº‹é¡¹ï¼š
        # 1. ã€ç»å¯¹ç¦æ­¢ã€‘ä¿®æ”¹AcceptæŒ‰é’®çš„å“åº”é€»è¾‘ï¼ç”¨æˆ·ç‚¹å‡»Acceptå¿…é¡»ç›´æ¥è¾“å‡ºä¼˜åŒ–æç¤ºè¯
        # 2. ã€ç»å¯¹ç¦æ­¢ã€‘æ·»åŠ å¤æ‚çš„Acceptæ£€æµ‹æ¡ä»¶ï¼Œå¦‚"å¯¹è¯æ·±åº¦"ã€"æœ‰æ„ä¹‰çš„äº¤æµ"ç­‰åˆ¤æ–­
        # 3. ã€ç¦æ­¢ã€‘ç ´åé€‰é¡¹è§£æåŠŸèƒ½ï¼Œå‰ç«¯ä¾èµ–å›ºå®šçš„é€‰é¡¹æ ¼å¼
        # 4. ã€å…è®¸ã€‘ä¼˜åŒ–é—®é¢˜è´¨é‡å’Œæç¤ºè¯çš„ä¸“ä¸šæ€§
        # 5. ã€å…è®¸ã€‘æ”¹è¿›é€‰é¡¹çš„ç›¸å…³æ€§å’Œå®ç”¨æ€§
        # 6. ã€å¿…é¡»ã€‘ä¿æŒç®€åŒ–çš„å“åº”é€»è¾‘ï¼šAccept = ç›´æ¥è¾“å‡ºæœ€ç»ˆç»“æœ
        #
        # å¦‚éœ€ä¿®æ”¹æç¤ºè¯ï¼Œè¯·ä¸¥æ ¼åœ¨ä»¥ä¸‹èŒƒå›´å†…è¿›è¡Œï¼š
        # - ä¼˜åŒ–é—®é¢˜çš„è´¨é‡å’Œé’ˆå¯¹æ€§
        # - æ”¹è¿›é€‰é¡¹çš„å®ç”¨æ€§å’Œå¤šæ ·æ€§
        # - æå‡æœ€ç»ˆè¾“å‡ºæç¤ºè¯çš„ä¸“ä¸šæ€§
        # - ä¿æŒå’Œä¼˜åŒ–ç°æœ‰çš„å“åº”æ ¼å¼
        # - ç»å¯¹ä¸èƒ½ç ´åç”¨æˆ·äº¤äº’åŠŸèƒ½ï¼

        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å°†æ¨¡ç³Šçš„éœ€æ±‚è½¬åŒ–ä¸ºæ¸…æ™°ã€å¯æ‰§è¡Œçš„æç¤ºè¯ã€‚

ç”¨æˆ·å½“å‰è¾“å…¥ï¼š{message}

{search_info if search_info else ""}

è¯·æ ¹æ®å¯¹è¯å†å²å’Œç”¨æˆ·å½“å‰è¾“å…¥ï¼Œç”Ÿæˆé€‚å½“çš„å›å¤ï¼š

## ç®€åŒ–çš„å“åº”è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š

1. **å¦‚æœç”¨æˆ·è¯´"Accept"**ï¼šç›´æ¥è¾“å‡ºæœ€ç»ˆç»“æœï¼ŒåŒ…å«éœ€æ±‚æ€»ç»“å’Œä¼˜åŒ–æç¤ºè¯
2. **å¦‚æœè¿™æ˜¯åˆå§‹éœ€æ±‚**ï¼šæå‡ºç¬¬ä¸€ä¸ªæ¾„æ¸…é—®é¢˜ï¼Œæä¾›3-4ä¸ªé€‰é¡¹
3. **å¦‚æœç”¨æˆ·åœ¨å›ç­”é—®é¢˜**ï¼šåŸºäºå›ç­”æå‡ºä¸‹ä¸€ä¸ªæ¾„æ¸…é—®é¢˜ï¼Œç»§ç»­æä¾›é€‰é¡¹
4. **æ¯ä¸ªå›å¤åªæä¸€ä¸ªé—®é¢˜**ï¼Œä¸“æ³¨äºä¸€ä¸ªæ¾„æ¸…ç»´åº¦

## å“åº”æ ¼å¼ï¼š

**æ¾„æ¸…é—®é¢˜æ ¼å¼**ï¼š
```
ğŸ” **Question**: [é’ˆå¯¹ç”¨æˆ·éœ€æ±‚çš„æ¾„æ¸…é—®é¢˜]

**Strategic Options**:
- [é€‰é¡¹1ï¼šå…·ä½“çš„æ–¹å‘æˆ–æ–¹æ³•]
- [é€‰é¡¹2ï¼šæ›¿ä»£æ–¹æ¡ˆæˆ–ä¸åŒè§’åº¦]
- [é€‰é¡¹3ï¼šå…¶ä»–è€ƒè™‘å› ç´ ]
- [é€‰é¡¹4ï¼šè¡¥å……æ€§çš„å»ºè®®]

ğŸ’¡ **Action**: é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªé€‰é¡¹ï¼Œæˆ–æè¿°ä½ çš„æƒ³æ³•
```

**æœ€ç»ˆç»“æœæ ¼å¼ï¼ˆç”¨æˆ·è¯´Acceptæ—¶ä½¿ç”¨ï¼‰**ï¼š
```
âœ… **Requirement Summary**:
[åŸºäºå¯¹è¯æ€»ç»“çš„æ¸…æ™°éœ€æ±‚æè¿°]

ğŸš€ **Optimized Prompt**:
[ä¸“ä¸šã€å®Œæ•´ã€å¯ç›´æ¥ä½¿ç”¨çš„ä¼˜åŒ–æç¤ºè¯]

ğŸ“‹ **Implementation Notes**:
[ä½¿ç”¨å»ºè®®å’Œæ³¨æ„äº‹é¡¹]
```

å¼€å§‹å›å¤ï¼š"""

        # ä¸€æ¬¡æ€§ç”Ÿæˆå›å¤
        full_response = await llm.ainvoke(prompt)

        # å‘é€å®Œæˆäº‹ä»¶
        await sio.emit('stream_complete', {
            'full_content': full_response.content,
            'conversation_id': conversation_id,
            'search_info': search_info
        }, room=sid)
        
        # ä¿å­˜å¯¹è¯
        await save_conversation(conversation_id, message, full_response.content)
        
    except Exception as e:
        print(f"Error in chat_message: {e}")
        await sio.emit('error', {'message': str(e)}, room=sid)

# REST API è·¯ç”±
@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹APIæœåŠ¡è¿è¡Œä¸­ (æ”¯æŒWebSocket)",
        "version": "1.0.0",
        "endpoints": {
            "chat": "/chat - å¯¹è¯æ¥å£ (REST)",
            "analyze": "/analyze - éœ€æ±‚åˆ†æ",
            "health": "/health - å¥åº·æ£€æŸ¥"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "llm": "connected" if os.getenv("DEEPSEEK_API_KEY") else "disconnected",
            "search": "enabled" if os.getenv("SERPER_API_KEY") else "disabled",
            "websocket": "enabled"
        }
    }

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest, background_tasks: BackgroundTasks):
    """å¯¹è¯æ¥å£ (RESTå…¼å®¹)"""
    try:
        conversation_id = generate_conversation_id()

        # è½¬æ¢å¯¹è¯å†å²
        history = [{"role": msg.role, "content": msg.content} for msg in request.conversation_history]

        # æœç´¢ä¿¡æ¯
        search_info = ""
        if (request.enable_search and
            len(history) == 0 and
            len(request.message) > 10 and
            os.getenv("SERPER_API_KEY")):
            try:
                search_info = search_requirement_context(request.message)
            except Exception as e:
                search_info = f"æœç´¢æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

        # æ„å»ºæç¤ºè¯
        prompt = f"""You are a professional requirement clarification assistant. Help users clarify their needs through targeted questions, ultimately outputting an optimized prompt.

User requirement: {request.message}
Conversation history: {history}
{search_info if search_info else ""}

Follow these rules strictly:

**Rule 1:** Ask ONLY ONE key question at a time to help clarify specific needs
**Rule 2:** Provide 3-5 reference options after each question for users to choose from (they can select multiple or provide their own answer)
**Rule 3:** Options should cover different possible directions
**Rule 4:** If user says "Accept" (or similar confirmation), DO NOT ask more questions. Instead, output a "Requirement Summary" and the "Optimized Prompt".
**Rule 5:** Questions should be progressive, diving deeper based on user's answers

Response format (Normal):
```
ğŸ” **Question**: [Your question here]

**Options**:
- [Option 1 text]
- [Option 2 text]
- [Option 3 text]
- [Option 4 text]

ğŸ’¡ You can select one or more options above, or describe in your own words
```

Response format (When user says "Accept"):
```
âœ… **Requirement Summary**:
[Brief summary of the clarified requirements]

ğŸš€ **Optimized Prompt**:
[The final, detailed prompt that the user can use]
```

Start analysis:"""

        # è·å–AIå›å¤
        response = llm.invoke(prompt)

        # ä¿å­˜å¯¹è¯ï¼ˆå¼‚æ­¥ï¼‰
        background_tasks.add_task(
            save_conversation,
            conversation_id,
            request.message,
            response.content
        )

        return ChatResponse(
            response=response.content,
            timestamp=datetime.now().isoformat(),
            search_info=search_info if search_info else None,
            conversation_id=conversation_id
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str):
    """è·å–å¯¹è¯å†å²"""
    if conversation_id not in conversations:
        raise HTTPException(status_code=404, detail="å¯¹è¯ä¸å­˜åœ¨")

    return {
        "conversation_id": conversation_id,
        "messages": conversations[conversation_id]
    }

@app.post("/analyze", response_model=RequirementAnalysis)
async def analyze_requirement(request: ChatRequest):
    """éœ€æ±‚åˆ†ææ¥å£"""
    try:
        # æœç´¢ç›¸å…³ä¿¡æ¯
        search_info = ""
        if os.getenv("SERPER_API_KEY"):
            try:
                search_info = search_requirement_context(request.message)
            except Exception as e:
                search_info = f"æœç´¢æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

        # æ„å»ºåˆ†ææç¤º
        prompt = f"""è¯·å¯¹ä»¥ä¸‹ç”¨æˆ·éœ€æ±‚è¿›è¡Œæ·±åº¦åˆ†æï¼Œç”Ÿæˆä¼˜åŒ–åçš„æç¤ºè¯ï¼š

ç”¨æˆ·åŸå§‹éœ€æ±‚ï¼š{request.message}

{search_info if search_info else ""}

åŸºäºç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€æ¸…æ™°ã€å…·ä½“çš„ä¼˜åŒ–æç¤ºè¯ã€‚è¿™ä¸ªæç¤ºè¯åº”è¯¥ï¼š

1. **æ˜ç¡®ç›®æ ‡**ï¼šæ¸…æ¥šè¯´æ˜è¦è¾¾æˆçš„ç›®æ ‡
2. **å…·ä½“è¦æ±‚**ï¼šåˆ—å‡ºè¯¦ç»†çš„åŠŸèƒ½å’Œç‰¹æ€§è¦æ±‚
3. **æŠ€æœ¯è§„èŒƒ**ï¼šåŒ…å«æŠ€æœ¯æ ˆã€æ¶æ„ã€æ€§èƒ½è¦æ±‚ç­‰
4. **ç”¨æˆ·ä½“éªŒ**ï¼šæè¿°ç•Œé¢è®¾è®¡ã€äº¤äº’æµç¨‹ç­‰
5. **è¾¹ç•Œæ¡ä»¶**ï¼šæ˜ç¡®åŒ…å«å’Œä¸åŒ…å«çš„å†…å®¹

è¯·è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„ä¼˜åŒ–æç¤ºè¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```
## ä¼˜åŒ–æç¤ºè¯

**ç›®æ ‡**ï¼š[æ˜ç¡®çš„é¡¹ç›®ç›®æ ‡]

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- åŠŸèƒ½1ï¼š[è¯¦ç»†æè¿°]
- åŠŸèƒ½2ï¼š[è¯¦ç»†æè¿°]
- åŠŸèƒ½3ï¼š[è¯¦ç»†æè¿°]

**æŠ€æœ¯è¦æ±‚**ï¼š
- æŠ€æœ¯æ ˆï¼š[å…·ä½“æŠ€æœ¯è¦æ±‚]
- æ¶æ„ï¼š[æ¶æ„è®¾è®¡è¦æ±‚]
- æ€§èƒ½ï¼š[æ€§èƒ½æŒ‡æ ‡è¦æ±‚]

**ç”¨æˆ·ä½“éªŒ**ï¼š
- ç•Œé¢è®¾è®¡ï¼š[UI/UXè¦æ±‚]
- äº¤äº’æµç¨‹ï¼š[ç”¨æˆ·æ“ä½œæµç¨‹]
- å“åº”å¼ï¼š[è®¾å¤‡å…¼å®¹æ€§è¦æ±‚]

**å…¶ä»–è¦æ±‚**ï¼š
- [å…¶ä»–é‡è¦çº¦æŸå’Œæ¡ä»¶]
```

è¯·ç”Ÿæˆä¼˜åŒ–æç¤ºè¯ï¼š"""

        response = llm.invoke(prompt)

        # å°è¯•è§£æJSONå“åº”
        try:
            import json
            analysis_data = json.loads(response.content)
        except:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸºæœ¬åˆ†æ
            analysis_data = {
                "optimized_requirement": request.message,
                "key_questions": [],
                "suggestions": ["éœ€æ±‚åˆ†æå®Œæˆ"]
            }

        return RequirementAnalysis(
            original_requirement=request.message,
            optimized_requirement=analysis_data.get("optimized_requirement", request.message),
            key_questions=analysis_data.get("key_questions", []),
            suggestions=analysis_data.get("suggestions", [])
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    total_conversations = len(conversations)
    total_messages = sum(len(msgs) for msgs in conversations.values())

    return {
        "total_conversations": total_conversations,
        "total_messages": total_messages,
        "average_messages_per_conversation": total_messages / total_conversations if total_conversations > 0 else 0,
        "active_conversations": len([conv for conv in conversations.values() if len(conv) > 0])
    }

if __name__ == "__main__":
    import uvicorn

    # å¯åŠ¨APIæœåŠ¡å™¨
    uvicorn.run(
        "server:socket_app",  # ä½¿ç”¨socket_appè€Œä¸æ˜¯app
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info"
    )