"""
éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ - ä¿®å¤ç‰ˆ
è§£å†³Agentè¿­ä»£é™åˆ¶é—®é¢˜
"""

import os
import streamlit as st
from dotenv import load_dotenv
from crewai import Agent, Task
from langchain_openai import ChatOpenAI

load_dotenv()

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
st.markdown(
    """
    <style>
    .main {
        padding-top: 2rem;
    }
    .title {
        text-align: center;
        color: #1f77b4;
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 1rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# è®¾ç½®LLM
@st.cache_resource
def get_llm():
    """ç¼“å­˜LLMå®ä¾‹"""
    return ChatOpenAI(
        model="deepseek-chat",
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        openai_api_base=os.getenv("DEEPSEEK_BASE_URL"),
    )


def load_prompt_from_file(file_path: str) -> str:
    """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ï¼Œé€šè¿‡æé—®å¸®åŠ©ç”¨æˆ·æ˜ç¡®éœ€æ±‚ã€‚"


@st.cache_resource
def create_conversation_agent():
    """åˆ›å»ºå¯¹è¯Agentï¼ˆç¼“å­˜ï¼‰"""
    prompt_content = load_prompt_from_file('example_prompt_template.txt')

    agent = Agent(
        role='éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹',
        goal='é€šè¿‡æé—®å¸®åŠ©ç”¨æˆ·æ¾„æ¸…çœŸå®éœ€æ±‚',
        backstory=prompt_content,
        verbose=False,
        llm=get_llm(),
        allow_delegation=False,
        max_iter=50  # å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°
    )
    return agent


def get_ai_response(user_input: str, agent):
    """è·å–AIå›å¤ - ä½¿ç”¨å•Agentæ¨¡å¼é¿å…è¿­ä»£é—®é¢˜"""
    try:
        # åˆ›å»ºä»»åŠ¡
        task = Task(
            description=f'ç”¨æˆ·åˆå§‹éœ€æ±‚ï¼š{user_input}\n\nè¯·ä½œä¸ºéœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ï¼Œæå‡ºç¬¬ä¸€ä¸ªå…³é”®é—®é¢˜æ¥å¸®åŠ©ç”¨æˆ·æ¾„æ¸…éœ€æ±‚ã€‚æä¾›Aã€Bã€Cã€Då››ä¸ªé€‰é¡¹ä¾›ç”¨æˆ·é€‰æ‹©ã€‚',
            agent=agent,
            expected_output='æå‡ºä¸€ä¸ªé’ˆå¯¹æ€§çš„é—®é¢˜ï¼ŒåŒ…å«A/B/C/Då››ä¸ªé€‰é¡¹'
        )

        # ç›´æ¥ä½¿ç”¨agentæ‰§è¡Œä»»åŠ¡ï¼Œä¸ä½¿ç”¨Crew
        result = agent.tools_executor.run(task=task)
        return result, True
    except Exception as e:
        return f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™ï¼š{str(e)}", False


def main():
    """ä¸»ç•Œé¢"""

    # æ ‡é¢˜
    st.markdown(
        """
        <h1 style='text-align: center; color: #1f77b4; margin-bottom: 0;'>
            ğŸ¤– éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹
        </h1>
        <p style='text-align: center; color: #666; margin-top: 0.5rem;'>
            é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„æé—®ï¼Œå¸®åŠ©æ‚¨æ˜ç¡®çœŸå®éœ€æ±‚
        </p>
        <hr style='margin: 1rem 0;'>
        """,
        unsafe_allow_html=True
    )

    # åˆ›å»ºAgent
    agent = create_conversation_agent()

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ã€‚\n\n"
                          "æˆ‘å°†é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„æé—®ï¼Œå¸®åŠ©ä½ æ˜ç¡®å’Œæ¾„æ¸…çœŸå®éœ€æ±‚ã€‚\n\n"
                          "ğŸ’¡ **ä½¿ç”¨æ–¹å¼ï¼š**\n"
                          "1. è¯·æè¿°ä½ çš„åˆå§‹æƒ³æ³•æˆ–éœ€æ±‚\n"
                          "2. æˆ‘ä¼šæå‡ºå…³é”®é—®é¢˜å¸®åŠ©ä½ æ¾„æ¸…\n"
                          "3. æä¾›A/B/C/Dé€‰é¡¹ä¾›ä½ é€‰æ‹©\n"
                          "4. å½“éœ€æ±‚è¶³å¤Ÿæ¸…æ™°æ—¶ï¼Œè¾“å…¥\"Accept\"è·å–å®Œæ•´çš„éœ€æ±‚åˆ†æ\n\n"
                          "è¯·å¼€å§‹æè¿°ä½ çš„éœ€æ±‚å§ï¼"
            }
        ]

    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("ğŸ’¬ è¯·æè¿°ä½ çš„éœ€æ±‚æˆ–æƒ³æ³•..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # è·å–AIå›å¤
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” AIæ­£åœ¨åˆ†æéœ€æ±‚..."):
                try:
                    # ä½¿ç”¨Agentç›´æ¥æ‰§è¡Œä»»åŠ¡
                    llm = get_llm()
                    prompt_content = load_prompt_from_file('example_prompt_template.txt')

                    full_prompt = f"""{prompt_content}

ç”¨æˆ·éœ€æ±‚ï¼š{prompt}

è¯·åˆ†æè¿™ä¸ªéœ€æ±‚ï¼Œå¹¶æå‡ºç¬¬ä¸€ä¸ªå…³é”®é—®é¢˜æ¥å¸®åŠ©ç”¨æˆ·æ¾„æ¸…éœ€æ±‚ã€‚ç¡®ä¿åªæå‡ºä¸€ä¸ªé—®é¢˜ï¼Œå¹¶æä¾›Aã€Bã€Cã€Då››ä¸ªé€‰é¡¹ä¾›ç”¨æˆ·é€‰æ‹©ã€‚

å¦‚æœè¿™æ˜¯ç”¨æˆ·çš„åˆå§‹éœ€æ±‚ï¼Œè¯·æå‡ºç¬¬ä¸€ä¸ªé—®é¢˜ã€‚
å¦‚æœç”¨æˆ·æ˜¯åœ¨å›ç­”ä¹‹å‰çš„é—®é¢˜ï¼Œè¯·åŸºäºç”¨æˆ·çš„å›ç­”æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜ã€‚
å¦‚æœç”¨æˆ·è¾“å…¥"Accept"ï¼Œè¯·åœæ­¢æé—®ï¼Œå¹¶ç”Ÿæˆå®Œæ•´çš„éœ€æ±‚åˆ†ææŠ¥å‘Šï¼ˆæŒ‰markdownæ ¼å¼ï¼ŒåŒ…å«åŸå§‹éœ€æ±‚ã€å…³é”®é—®ç­”ã€ä¼˜åŒ–åçš„éœ€æ±‚ã€å»ºè®®å®ç°æ–¹æ¡ˆï¼‰ã€‚

å¼€å§‹ï¼š
"""

                    response = llm.invoke(full_prompt)
                    response_text = response.content

                    # æ˜¾ç¤ºå›å¤
                    st.markdown(response_text)

                    # æ·»åŠ AIå›å¤åˆ°å†å²
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response_text
                    })

                except Exception as e:
                    st.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™ï¼š{str(e)}")

        # é‡æ–°è¿è¡Œä»¥åˆ·æ–°ç•Œé¢
        st.rerun()

    # æ¸…ç©ºæŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", type="secondary"):
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "âœ… å¯¹è¯å·²æ¸…ç©ºã€‚æœ‰ä»€ä¹ˆæ–°éœ€æ±‚éœ€è¦æ¾„æ¸…å—ï¼Ÿ"
            }
        ]
        st.rerun()

    # é¡µè„š
    st.markdown(
        """
        <hr style='margin: 2rem 0 1rem 0;'>
        <p style='text-align: center; color: #888; font-size: 0.8rem;'>
            Powered by CrewAI + DeepSeek | éœ€æ±‚æ¾„æ¸…åŠ©æ‰‹ v1.0
        </p>
        """,
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
